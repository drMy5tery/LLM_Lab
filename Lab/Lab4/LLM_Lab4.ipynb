{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f89d587-9525-4a64-b62c-5ef7d8ad88c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: SpeechRecognition in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: gtts in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (2.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.27 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n",
      "Requirement already satisfied: PyAudio in d:\\anacondanavigator\\envs\\tf\\lib\\site-packages (0.2.14)\n",
      "Collecting rogue\n",
      "  Downloading rogue-0.0.2.tar.gz (5.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: rogue\n",
      "  Building wheel for rogue (setup.py): started\n",
      "  Building wheel for rogue (setup.py): finished with status 'done'\n",
      "  Created wheel for rogue: filename=rogue-0.0.2-py3-none-any.whl size=7218 sha256=463a933dbcd4d9b58a8568b6ed018a81ce23a3035010095aeb6eff420867f7ae\n",
      "  Stored in directory: c:\\users\\dhanush adithiya\\appdata\\local\\pip\\cache\\wheels\\88\\65\\0c\\e2d3efe66c4b48cb42ed2a2c5b310b9b5884c42238096f4414\n",
      "Successfully built rogue\n",
      "Installing collected packages: rogue\n",
      "Successfully installed rogue-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n",
    "!pip install SpeechRecognition\n",
    "!pip install gtts\n",
    "!pip install PyAudio\n",
    "!pip install rogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63614369-2116-4354-b779-e699abe4ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import speech_recognition as sr\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2bed26d-1653-4a6b-9851-9af63a5e5014",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class QuestionBot:\n",
    "    def __init__(self, language=\"en\"):\n",
    "        self.language = language\n",
    "        if language == \"en\":\n",
    "            self.model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "            self.sr_lang = \"en-US\"\n",
    "            self.tts_lang = \"en\"\n",
    "        elif language == \"hi\":\n",
    "            self.model_name = \"deepset/xlm-roberta-base-squad2\"\n",
    "            self.sr_lang = \"hi-IN\"\n",
    "            self.tts_lang = \"hi\"\n",
    "        elif language == \"es\":\n",
    "            self.model_name = \"deepset/xlm-roberta-base-squad2\"\n",
    "            self.sr_lang = \"es-ES\"\n",
    "            self.tts_lang = \"es\"\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported language. Choose from 'en', 'hi', or 'es'.\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(self.model_name)\n",
    "        self.text = \"\"\n",
    "        \n",
    "        # Initialize ROUGE scorer\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        \n",
    "    def parse_pdf(self, path_to_file):\n",
    "        try:\n",
    "            doc = fitz.open(path_to_file)\n",
    "            self.text = \"\"\n",
    "            for page in doc:\n",
    "                self.text += page.get_text()\n",
    "            doc.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_voice_input(self):\n",
    "        r = sr.Recognizer()\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                print(\"Ask your question...\")\n",
    "                r.adjust_for_ambient_noise(source, duration=1)\n",
    "                audio = r.listen(source, timeout=10, phrase_time_limit=5)\n",
    "            \n",
    "            question = r.recognize_google(audio, language=self.sr_lang)\n",
    "            print(\"You asked:\", question)\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Speech recognition error: {e}\")\n",
    "            return None\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"No speech detected within timeout.\")\n",
    "            return None\n",
    "    \n",
    "    def get_answer(self, question):\n",
    "        if not self.text:\n",
    "            return \"No document loaded. Please parse a PDF first.\"\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                question,\n",
    "                self.text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding=True\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            \n",
    "            answer_start = torch.argmax(outputs.start_logits)\n",
    "            answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "            \n",
    "            # Handle case where answer_end is before answer_start\n",
    "            if answer_end <= answer_start:\n",
    "                return \"Could not find a suitable answer in the document.\"\n",
    "            \n",
    "            answer = self.tokenizer.convert_tokens_to_string(\n",
    "                self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
    "            )\n",
    "            \n",
    "            return answer.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error generating answer: {e}\"\n",
    "    \n",
    "    def play_answer(self, answer):\n",
    "        if not answer or answer.startswith(\"Error\") or answer.startswith(\"Could not\"):\n",
    "            print(\"Cannot play invalid answer:\", answer)\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            print(\"Answer:\", answer)\n",
    "            tts = gTTS(text=answer, lang=self.tts_lang)\n",
    "            tts.save(\"answer.mp3\")\n",
    "            \n",
    "            # Cross-platform audio playing\n",
    "            if os.name == 'nt':  # Windows\n",
    "                os.system(\"start answer.mp3\")\n",
    "            elif os.name == 'posix':  # Mac/Linux\n",
    "                os.system(\"afplay answer.mp3\")  # Mac\n",
    "                # os.system(\"mpg123 answer.mp3\")  # Linux alternative\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing answer: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def evaluate_bleu(self, reference, candidate):\n",
    "        try:\n",
    "            # Tokenize the texts\n",
    "            reference_tokens = reference.lower().split()\n",
    "            candidate_tokens = candidate.lower().split()\n",
    "            \n",
    "            # Use smoothing function to handle edge cases\n",
    "            smoothie = SmoothingFunction().method4\n",
    "            \n",
    "            # Calculate BLEU score\n",
    "            bleu_score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "            \n",
    "            return round(bleu_score, 4)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating BLEU score: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_rouge(self, reference, candidate):\n",
    "        try:\n",
    "            scores = self.rouge_scorer.score(reference, candidate)\n",
    "            \n",
    "            rouge_scores = {\n",
    "                'rouge1': {\n",
    "                    'precision': round(scores['rouge1'].precision, 4),\n",
    "                    'recall': round(scores['rouge1'].recall, 4),\n",
    "                    'fmeasure': round(scores['rouge1'].fmeasure, 4)\n",
    "                },\n",
    "                'rouge2': {\n",
    "                    'precision': round(scores['rouge2'].precision, 4),\n",
    "                    'recall': round(scores['rouge2'].recall, 4),\n",
    "                    'fmeasure': round(scores['rouge2'].fmeasure, 4)\n",
    "                },\n",
    "                'rougeL': {\n",
    "                    'precision': round(scores['rougeL'].precision, 4),\n",
    "                    'recall': round(scores['rougeL'].recall, 4),\n",
    "                    'fmeasure': round(scores['rougeL'].fmeasure, 4)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return rouge_scores\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ROUGE scores: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def run(self, pdf_path):\n",
    "        if not self.parse_pdf(pdf_path):\n",
    "            return\n",
    "        \n",
    "        question = self.get_voice_input()\n",
    "        if not question:\n",
    "            print(\"Voice input failed or no question detected.\")\n",
    "            return\n",
    "        \n",
    "        answer = self.get_answer(question)\n",
    "        print(\"Answer:\", answer)\n",
    "        self.play_answer(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e3de2-04b1-42a1-bac4-c2c4dd750fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cc022c3-3ae5-47f9-a9b9-29a530210ca1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question...\n",
      "You asked: fin GPT\n",
      "Answer: [SEP]\n",
      "Answer: [SEP]\n",
      "BLEU Score: 0\n",
      "ROUGE Score: {'rouge1': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}, 'rouge2': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}, 'rougeL': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "bot = QuestionBot(language=\"en\")\n",
    "\n",
    "bot.parse_pdf(\"english.pdf\")\n",
    "\n",
    "question = bot.get_voice_input()\n",
    "\n",
    "if question:\n",
    "    answer = bot.get_answer(question)\n",
    "    print(\"Answer:\", answer)\n",
    "\n",
    "    bot.play_answer(answer)\n",
    "\n",
    "    reference = \"FinGPT is an open-source framework specifically designed for developing Large Language Models (LLMs) tailored to the finance sector. Unlike proprietary models like BloombergGPT\"\n",
    "    print(\"BLEU Score:\", bot.evaluate_bleu(reference, answer))\n",
    "    print(\"ROUGE Score:\", bot.evaluate_rouge(reference, answer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c62668-716e-43df-81e7-8b638f2df46c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bot_hi = QuestionBot(language=\"hi\")\n",
    "bot_hi.parse_pdf(\"hindi.pdf\")\n",
    "\n",
    "question_hi = bot_hi.get_voice_input()\n",
    "\n",
    "if question_hi:\n",
    "    answer_hi = bot_hi.get_answer(question_hi)\n",
    "    print(\"Answer (Hindi):\", answer_hi)\n",
    "\n",
    "    bot_hi.play_answer(answer_hi)\n",
    "\n",
    "    reference_hi = \"à¤­à¤¾à¤°à¤¤ à¤à¤• à¤µà¤¿à¤µà¤¿à¤§à¤¤à¤¾à¤“à¤‚ à¤¸à¥‡ à¤­à¤°à¤¾ à¤¦à¥‡à¤¶ à¤¹à¥ˆ à¤œà¤¹à¤¾à¤ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®, à¤­à¤¾à¤·à¤¾à¤à¤ à¤”à¤° à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤¯à¤¾à¤ à¤à¤• à¤¸à¤¾à¤¥ coexist à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤\"\n",
    "    \n",
    "    print(\"BLEU Score (Hindi):\", bot_hi.evaluate_bleu(reference_hi, answer_hi))\n",
    "    print(\"ROUGE Score (Hindi):\", bot_hi.evaluate_rouge(reference_hi, answer_hi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475271f2-13bf-4316-aebd-dbc1d638f735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c12f97-c6e1-4a68-b7fb-8223337ed6e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bot_es = QuestionBot(language=\"es\")\n",
    "bot_es.parse_pdf(\"spanish.pdf\")\n",
    "\n",
    "question_es = bot_es.get_voice_input()\n",
    "\n",
    "if question_es:\n",
    "    answer_es = bot_es.get_answer(question_es)\n",
    "    print(\"Answer (Spanish):\", answer_es)\n",
    "\n",
    "    bot_es.play_answer(answer_es)\n",
    "\n",
    "    reference_es = \"EspaÃ±a es un paÃ­s con una rica historia y una diversidad cultural impresionante.\"\n",
    "    \n",
    "    print(\"BLEU Score (Spanish):\", bot_es.evaluate_bleu(reference_es, answer_es))\n",
    "    print(\"ROUGE Score (Spanish):\", bot_es.evaluate_rouge(reference_es, answer_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5878d-78bd-4a03-8229-370223c9561d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ccefbdf-b95d-402a-9002-4fcf30cf6ed1",
   "metadata": {},
   "source": [
    "| Model Type         | Model Name                                                      |\n",
    "| ------------------ | --------------------------------------------------------------- |\n",
    "| Foundation (EN)    | `bert-large-uncased-whole-word-masking-finetuned-squad`         |\n",
    "| Indic (HI)         | `deepset/xlm-roberta-base-squad2` (Multilingual; handles Hindi) |\n",
    "| International (ES) | `deepset/xlm-roberta-base-squad2`   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e7f04-33ec-4df5-b6d0-5dbe0c61ea8d",
   "metadata": {},
   "source": [
    "ðŸ“„ PDF Text Extraction: via PyMuPDF\n",
    "\n",
    "ðŸ—£ï¸ Voice Input: Google STT via speech_recognition library\n",
    "\n",
    "ðŸ¤– QA Inference: HuggingFace Transformers with AutoModelForQuestionAnswering\n",
    "\n",
    "ðŸ”Š Voice Output: via gTTS (supports en, hi, es languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca3eaf-8671-421f-8090-3046b2ada0c9",
   "metadata": {},
   "source": [
    "| **Aspect**                  | **Foundation Model (English)** `bert-large-uncased-whole-word-masking-finetuned-squad` | **Indic Model (Hindi)** `xlm-roberta-base-squad2`          | **International Model (Spanish)** `xlm-roberta-base-squad2` |\n",
    "| --------------------------- | -------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ----------------------------------------------------------- |\n",
    "| **Language Fluency**        | âœ…âœ… (Very fluent, native-level for English)                                             | âœ… (Decent fluency, occasional awkward phrasing)            | âœ…âœ… (Fluent for Spanish, better than Hindi)                  |\n",
    "| **Named Entity Handling**   | âœ…âœ… (Strong entity recognition for English names, dates, etc.)                          | âœ… (Sometimes misses local named entities)                  | âœ… (Handles Spanish entities well, but not perfect)          |\n",
    "| **Accuracy of Extraction**  | **High** (optimized on SQuAD)                                                          | **Medium** (xlm-roberta is generalist, not Indic-specific) | **Medium** (xlm-roberta is multilingual, decent accuracy)   |\n",
    "| **Speech-to-Text Accuracy** | âœ…âœ… (Google Speech in `en-US` is very accurate)                                         | âœ… (Decent, but errors increase with accents or dialects)   | âœ…âœ… (Spanish `es-ES` recognition is well-supported)          |\n",
    "| **Text-to-Speech Quality**  | **Good** (gTTS `en` has natural pronunciation and intonation)                          | **Moderate** (gTTS `hi` often sounds robotic)              | **Good** (gTTS `es` produces pleasant and accurate output)  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42347f2b-0913-48b6-bf5a-6fab323f0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionBot:\n",
    "    def __init__(self, language=\"en\"):\n",
    "        self.language = language\n",
    "        if language == \"en\":\n",
    "            self.model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "            self.sr_lang = \"en-US\"\n",
    "            self.tts_lang = \"en\"\n",
    "        \n",
    "        elif language == \"hi\":\n",
    "            self.model_name = \"LingoIITGN/ganga-1b\"\n",
    "            self.sr_lang = \"hi-IN\"\n",
    "            self.tts_lang = \"hi\"\n",
    "        \n",
    "        elif language == \"es\":\n",
    "            self.model_name = \"mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\"\n",
    "            self.sr_lang = \"es-ES\"\n",
    "            self.tts_lang = \"es\"\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported language. Choose from 'en', 'hi', or 'es'.\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(self.model_name)\n",
    "        self.text = \"\"\n",
    "        \n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        \n",
    "    def parse_pdf(self, path_to_file):\n",
    "        try:\n",
    "            doc = fitz.open(path_to_file)\n",
    "            self.text = \"\"\n",
    "            for page in doc:\n",
    "                self.text += page.get_text()\n",
    "            doc.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_voice_input(self):\n",
    "        r = sr.Recognizer()\n",
    "        try:\n",
    "            with sr.Microphone() as source:\n",
    "                print(\"Ask your question...\")\n",
    "                r.adjust_for_ambient_noise(source, duration=1)\n",
    "                audio = r.listen(source, timeout=10, phrase_time_limit=5)\n",
    "            \n",
    "            question = r.recognize_google(audio, language=self.sr_lang)\n",
    "            print(\"You asked:\", question)\n",
    "            return question\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Speech recognition error: {e}\")\n",
    "            return None\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"No speech detected within timeout.\")\n",
    "            return None\n",
    "    \n",
    "    def get_answer(self, question):\n",
    "        if not self.text:\n",
    "            return \"No document loaded. Please parse a PDF first.\"\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer.encode_plus(\n",
    "                question,\n",
    "                self.text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding=True\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "            \n",
    "            answer_start = torch.argmax(outputs.start_logits)\n",
    "            answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "            \n",
    "            # Handle case where answer_end is before answer_start\n",
    "            if answer_end <= answer_start:\n",
    "                return \"Could not find a suitable answer in the document.\"\n",
    "            \n",
    "            answer = self.tokenizer.convert_tokens_to_string(\n",
    "                self.tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
    "            )\n",
    "            \n",
    "            return answer.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error generating answer: {e}\"\n",
    "    \n",
    "    def play_answer(self, answer):\n",
    "        if not answer or answer.startswith(\"Error\") or answer.startswith(\"Could not\"):\n",
    "            print(\"Cannot play invalid answer:\", answer)\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            print(\"Answer:\", answer)\n",
    "            tts = gTTS(text=answer, lang=self.tts_lang)\n",
    "            tts.save(\"answer.mp3\")\n",
    "            \n",
    "            if os.name == 'nt':\n",
    "                os.system(\"start answer.mp3\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing answer: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def evaluate_bleu(self, reference, candidate):\n",
    "        try:\n",
    "            reference_tokens = reference.lower().split()\n",
    "            candidate_tokens = candidate.lower().split()\n",
    "            \n",
    "            smoothie = SmoothingFunction().method4\n",
    "            \n",
    "            bleu_score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "            \n",
    "            return round(bleu_score, 4)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating BLEU score: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def evaluate_rouge(self, reference, candidate):\n",
    "        try:\n",
    "            scores = self.rouge_scorer.score(reference, candidate)\n",
    "            \n",
    "            rouge_scores = {\n",
    "                'rouge1': {\n",
    "                    'precision': round(scores['rouge1'].precision, 4),\n",
    "                    'recall': round(scores['rouge1'].recall, 4),\n",
    "                    'fmeasure': round(scores['rouge1'].fmeasure, 4)\n",
    "                },\n",
    "                'rouge2': {\n",
    "                    'precision': round(scores['rouge2'].precision, 4),\n",
    "                    'recall': round(scores['rouge2'].recall, 4),\n",
    "                    'fmeasure': round(scores['rouge2'].fmeasure, 4)\n",
    "                },\n",
    "                'rougeL': {\n",
    "                    'precision': round(scores['rougeL'].precision, 4),\n",
    "                    'recall': round(scores['rougeL'].recall, 4),\n",
    "                    'fmeasure': round(scores['rougeL'].fmeasure, 4)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return rouge_scores\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating ROUGE scores: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def run(self, pdf_path):\n",
    "        if not self.parse_pdf(pdf_path):\n",
    "            return\n",
    "        \n",
    "        question = self.get_voice_input()\n",
    "        if not question:\n",
    "            print(\"Voice input failed or no question detected.\")\n",
    "            return\n",
    "        \n",
    "        answer = self.get_answer(question)\n",
    "        print(\"Answer:\", answer)\n",
    "        self.play_answer(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67febda4-7cc2-42ee-8198-8787a9a78646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MistralForQuestionAnswering were not initialized from the model checkpoint at LingoIITGN/ganga-1b and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question...\n",
      "You asked: à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤ à¤µà¤¿à¤µà¤¾à¤¹ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤‡à¤\n",
      "Answer (Hindi): à¤à¤• à¤µà¤¿à¤µà¤¿à¤§à¤¤à¤¾à¤“à¤‚ à¤¸à¥‡ à¤­à¤°à¤¾ à¤¦à¥‡à¤¶ à¤¹à¥ˆ à¤œà¤¹à¤¾à¤ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®, à¤­à¤¾à¤·à¤¾à¤à¤ à¤”à¤° à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤¯à¤¾à¤ à¤à¤• à¤¸à¤¾à¤¥ coexist à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤ \n",
      "à¤‡à¤¸à¤•à¥€ à¤à¤¤à¤¿à¤¹à¤¾à¤¸à¤¿à¤• à¤§à¤°à¥‹à¤¹à¤°, à¤œà¥ˆà¤¸à¥‡ à¤•à¤¿ à¤¤à¤¾à¤œ\n",
      "Answer: à¤à¤• à¤µà¤¿à¤µà¤¿à¤§à¤¤à¤¾à¤“à¤‚ à¤¸à¥‡ à¤­à¤°à¤¾ à¤¦à¥‡à¤¶ à¤¹à¥ˆ à¤œà¤¹à¤¾à¤ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®, à¤­à¤¾à¤·à¤¾à¤à¤ à¤”à¤° à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤¯à¤¾à¤ à¤à¤• à¤¸à¤¾à¤¥ coexist à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤ \n",
      "à¤‡à¤¸à¤•à¥€ à¤à¤¤à¤¿à¤¹à¤¾à¤¸à¤¿à¤• à¤§à¤°à¥‹à¤¹à¤°, à¤œà¥ˆà¤¸à¥‡ à¤•à¤¿ à¤¤à¤¾à¤œ\n",
      "BLEU Score (Hindi): 0.72\n",
      "ROUGE Score (Hindi): {'rouge1': {'precision': 1.0, 'recall': 1.0, 'fmeasure': 1.0}, 'rouge2': {'precision': 0.0, 'recall': 0.0, 'fmeasure': 0.0}, 'rougeL': {'precision': 1.0, 'recall': 1.0, 'fmeasure': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "bot_hi = QuestionBot(language=\"hi\")\n",
    "bot_hi.parse_pdf(\"hindi.pdf\")\n",
    "\n",
    "question_hi = bot_hi.get_voice_input()\n",
    "\n",
    "if question_hi:\n",
    "    answer_hi = bot_hi.get_answer(question_hi)\n",
    "    print(\"Answer (Hindi):\", answer_hi)\n",
    "\n",
    "    bot_hi.play_answer(answer_hi)\n",
    "\n",
    "    reference_hi = \"à¤­à¤¾à¤°à¤¤ à¤à¤• à¤µà¤¿à¤µà¤¿à¤§à¤¤à¤¾à¤“à¤‚ à¤¸à¥‡ à¤­à¤°à¤¾ à¤¦à¥‡à¤¶ à¤¹à¥ˆ à¤œà¤¹à¤¾à¤ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®, à¤­à¤¾à¤·à¤¾à¤à¤ à¤”à¤° à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿à¤¯à¤¾à¤ à¤à¤• à¤¸à¤¾à¤¥ coexist à¤•à¤°à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤\"\n",
    "    \n",
    "    print(\"BLEU Score (Hindi):\", bot_hi.evaluate_bleu(reference_hi, answer_hi))\n",
    "    print(\"ROUGE Score (Hindi):\", bot_hi.evaluate_rouge(reference_hi, answer_hi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "749b3bf1-926b-4d6a-a9bc-e1dfab92819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question...\n",
      "You asked: finance and what factors\n",
      "Answer (English): influenced by a multitude of factors. these factors can be anything from russia invading ukraine to trump â€™ s new tariff system\n",
      "Answer: influenced by a multitude of factors. these factors can be anything from russia invading ukraine to trump â€™ s new tariff system\n",
      "BLEU Score (English): 0.5889\n",
      "ROUGE Score (English): {'rouge1': {'precision': 1.0, 'recall': 0.75, 'fmeasure': 0.8571}, 'rouge2': {'precision': 1.0, 'recall': 0.7407, 'fmeasure': 0.8511}, 'rougeL': {'precision': 1.0, 'recall': 0.75, 'fmeasure': 0.8571}}\n"
     ]
    }
   ],
   "source": [
    "bot_en = QuestionBot(language=\"en\")\n",
    "bot_en.parse_pdf(\"english.pdf\")\n",
    "\n",
    "question_en = bot_en.get_voice_input()\n",
    "\n",
    "if question_en:\n",
    "    answer_en = bot_en.get_answer(question_en)\n",
    "    print(\"Answer (English):\", answer_en)\n",
    "\n",
    "    bot_en.play_answer(answer_en)\n",
    "\n",
    "    reference_en = \"Finance is an intricate field, it is influenced by a multitude of factors. These factors can be anything from Russia invading Ukraine to Trumpâ€™s new tariff system.\"\n",
    "    \n",
    "    print(\"BLEU Score (English):\", bot_en.evaluate_bleu(reference_en, answer_en))\n",
    "    print(\"ROUGE Score (English):\", bot_en.evaluate_rouge(reference_en, answer_en))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7066494d-a013-44ec-96b7-7f28a7110179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d67f9e2e1254bdc8ff676dc8f64d762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AnacondaNavigator\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dhanush Adithiya\\.cache\\huggingface\\hub\\models--mrm8488--bert-base-spanish-wwm-cased-finetuned-spa-squad2-es. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c1c8d716b94a32af0b42b04fa5a1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ac609df7f54196a8bd807d6457a155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872252ebab5b4925b6ac9e32f406bab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0029316a8614265a0cc365be8bb5d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer (Spanish): madrid, barcelona y sevilla\n",
      "Answer: madrid, barcelona y sevilla\n",
      "BLEU Score (Spanish): 0.0639\n",
      "ROUGE Score (Spanish): {'rouge1': {'precision': 1.0, 'recall': 0.25, 'fmeasure': 0.4}, 'rouge2': {'precision': 1.0, 'recall': 0.2, 'fmeasure': 0.3333}, 'rougeL': {'precision': 1.0, 'recall': 0.25, 'fmeasure': 0.4}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb03dce68ca64bb6bb903a2ebaeb2771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bot_es = QuestionBot(language=\"es\")  \n",
    "bot_es.parse_pdf(\"spanish.pdf\") \n",
    "\n",
    "question_es = \"Â¿CuÃ¡les son algunas ciudades famosas de EspaÃ±a y por quÃ© lo son?\"  \n",
    "if question_es:\n",
    "    answer_es = bot_es.get_answer(question_es)\n",
    "    print(\"Answer (Spanish):\", answer_es)\n",
    "\n",
    "    bot_es.play_answer(answer_es)\n",
    "\n",
    "    reference_es = \"Ciudades como Madrid, Barcelona y Sevilla son famosas por su arquitectura, gastronomÃ­a y vida nocturna.\"\n",
    "    \n",
    "    print(\"BLEU Score (Spanish):\", bot_es.evaluate_bleu(reference_es, answer_es))\n",
    "    print(\"ROUGE Score (Spanish):\", bot_es.evaluate_rouge(reference_es, answer_es))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abfc4db-7c20-4208-b0ca-56f04cae9195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
